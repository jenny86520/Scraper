import argparse
import os
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import NoSuchElementException
from urllib.parse import quote
import time
import datetime

output_dir = "wenku8_novel"
next_btn_text = "ä¸‹ä¸€é¡µ"


def get_novel_title(driver):
    """æŠ“å–å°èªªåç¨±ä½œç‚ºæª”åä¸¦åŠ ä¸Šæ™‚é–“"""
    try:
        linkleft = driver.find_element(By.ID, "linkleft")
        a_tags = linkleft.find_elements(By.TAG_NAME, "a")
        if len(a_tags) >= 3:
            title = a_tags[2].text.strip()
            # ç§»é™¤ Windows ä¸å…è¨±çš„å­—å…ƒ
            title = re.sub(r'[\\/:"*?<>|]', "", title)
        else:
            title = "novel"

        # åŠ ä¸Šæ™‚é–“
        now = datetime.datetime.now()
        timestamp = now.strftime("%Y%m%d_%H%M")
        filename = f"{title}_{timestamp}"
        return filename
    except Exception:
        return "novel"


def scrape_all(start_url, start_page=None, end_page=None):
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--lang=zh-TW")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )

    service = Service()
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.get(start_url)
    time.sleep(2)

    # æŠ“å°èªªåç¨±
    os.makedirs(output_dir, exist_ok=True)
    novel_title = get_novel_title(driver)
    output_filename = os.path.join(output_dir, f"{novel_title}.txt")
    log_filename = os.path.join(output_dir, f"{novel_title}_log.txt")
    print(f"ğŸ“„ è¼¸å‡ºæª”æ¡ˆ: {output_filename}")

    page_count = 1
    start_time = time.time()

    with open(output_filename, "w", encoding="utf-8") as f, open(
        log_filename, "a", encoding="utf-8"
    ) as log:
        f.writelines(f"ã€Š{novel_title}ã€‹")
        log.write(f"\n--- é–‹å§‹æŠ“å– {datetime.datetime.now()} ---\n")
        log.write(f"èµ·å§‹ç¶²å€: {start_url}\n\n")

        # å¦‚æœæŒ‡å®šèµ·å§‹é ï¼Œå…ˆè·³åˆ°è©²é 
        if start_page and start_page > 1:
            current_page = 1
            while current_page < start_page:
                try:
                    next_btn = driver.find_element(By.LINK_TEXT, next_btn_text)
                    next_btn.click()
                    current_page += 1
                    page_count += 1
                    time.sleep(1.2)
                except NoSuchElementException:
                    print(
                        f"âš ï¸ ç„¡æ³•åˆ°é”ç¬¬ {start_page} é ï¼Œå¾ç¬¬ {current_page} é é–‹å§‹æŠ“å–"
                    )
                    log.write(
                        f"âš ï¸ ç„¡æ³•åˆ°é”ç¬¬ {start_page} é ï¼Œå¾ç¬¬ {current_page} é é–‹å§‹æŠ“å–\n"
                    )
                    break

        # é–‹å§‹æŠ“å–
        while True:
            current_url = driver.current_url
            elapsed = time.time() - start_time
            chapter_name = driver.title.split("-")[0]
            print(f"ğŸ“„ã€{chapter_name}ã€‘{current_url} | ç¶“éæ™‚é–“ {int(elapsed)} ç§’")

            try:
                content_div = driver.find_element(By.ID, "content")
                text = content_div.text.strip()
                if text:
                    f.write(f"\n\nã€{chapter_name}ã€‘\n\n")
                    f.write(text)
                else:
                    raise ValueError("æ‰¾ä¸åˆ°æ­£æ–‡å…§å®¹")

                # å¦‚æœåˆ°é”æŒ‡å®šçµæŸé ï¼Œåœæ­¢
                if end_page and page_count >= end_page:
                    print(f"âœ… å·²é”æŒ‡å®šé æ•¸ï¼ˆ{end_page} é ï¼‰ï¼ŒæŠ“å–å®Œæˆã€‚")
                    log.write(f"âœ… å·²é”æŒ‡å®šé æ•¸ï¼ˆ{end_page} é ï¼‰ï¼ŒæŠ“å–å®Œæˆã€‚\n")
                    break

                # å˜—è©¦ä¸‹ä¸€é 
                try:
                    next_btn = driver.find_element(By.LINK_TEXT, next_btn_text)
                    next_btn.click()
                    page_count += 1
                    time.sleep(1.2)
                except NoSuchElementException:
                    print("âœ… å·²ç¶“æ˜¯æœ€å¾Œä¸€é ï¼ŒæŠ“å–å®Œæˆã€‚")
                    log.write("âœ… å·²ç¶“æ˜¯æœ€å¾Œä¸€é ï¼ŒæŠ“å–å®Œæˆã€‚\n")
                    break

            except Exception as e:
                error_msg = f"âš ï¸ {chapter_name}éŒ¯èª¤ ({type(e).__name__}): {e}"
                print(error_msg)
                log.write(f"{error_msg}\nURL: {current_url}\n\n")
                # å˜—è©¦ä¸‹ä¸€é 
                try:
                    next_btn = driver.find_element(By.LINK_TEXT, next_btn_text)
                    next_btn.click()
                    page_count += 1
                    time.sleep(1.2)
                except NoSuchElementException:
                    print("âŒ æ‰¾ä¸åˆ°ä¸‹ä¸€é æŒ‰éˆ•ï¼ŒçµæŸã€‚")
                    log.write("âŒ æ‰¾ä¸åˆ°ä¸‹ä¸€é æŒ‰éˆ•ï¼ŒçµæŸã€‚\n")
                    break

    driver.quit()
    print(f"\nğŸ“„ å°èªªå…§å®¹ï¼š {output_filename}")
    print(f"â›” éŒ¯èª¤æ—¥èªŒï¼š {log_filename}")


if __name__ == "__main__":
    print("è½»å°è¯´æ–‡åº“ çˆ¬èŸ²...")
    parser = argparse.ArgumentParser(description="è½»å°è¯´æ–‡åº“ çˆ¬èŸ²")
    parser.add_argument(
        "start_url",
        help="èµ·å§‹ç¶²å€ï¼ˆä¾‹å¦‚ï¼šhttps://www.wenku8.net/novel/2/2654/102261.htmï¼‰",
    )
    parser.add_argument(
        "pages",
        nargs="*",
        type=int,
        help="å¯é¸ï¼šèµ·å§‹é  çµæŸé ï¼ˆä¾‹å¦‚ 3 10ï¼Œä¸è¼¸å…¥å‰‡æŠ“åˆ°æœ€å¾Œä¸€é ï¼‰",
    )
    args = parser.parse_args()

    start_page = args.pages[0] if len(args.pages) >= 1 else None
    end_page = args.pages[1] if len(args.pages) >= 2 else None

    scrape_all(args.start_url, start_page, end_page)
